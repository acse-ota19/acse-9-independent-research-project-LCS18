{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Laura Su (GitHub: LCS18)\"\"\"\n",
    "%pylab inline\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# from livelossplot import PlotLosses\n",
    "# from pycm import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"\n",
    "    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n",
    "    torch.backends.cudnn.enabled   = False\n",
    "\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda installed! Running on GPU!\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
    "    print(\"Cuda installed! Running on GPU!\")\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print(\"No GPU available!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "GeForce 930MX\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing a custom dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset __getitem__ should return:\n",
    "\n",
    "- image: a PIL Image of size (H, W)\n",
    "- target: a dict containing the following fields\n",
    "    - boxes (FloatTensor[N, 4]): the coordinates of the N bounding boxes in [x0, y0, x1, y1] format, ranging from 0 to W and 0 to H\n",
    "    - labels (Int64Tensor[N]): the label for each bounding box\n",
    "    - image_id (Int64Tensor[1]): an image identifier. It should be unique between all the images in the dataset, and is used during evaluation\n",
    "    - area (Tensor[N]): The area of the bounding box. This is used during evaluation with the COCO metric, to separate the metric scores between small, medium and large boxes.\n",
    "    - iscrowd (UInt8Tensor[N]): instances with iscrowd=True will be ignored during evaluation.\n",
    "    - (optionally) masks (UInt8Tensor[N, H, W]): The segmentation masks for each one of the objects\n",
    "    - (optionally) keypoints (FloatTensor[N, K, 3]): For each one of the N objects, it contains the K keypoints in [x, y, visibility] format, defining the object. visibility=0 means that the keypoint is not visible. Note that for data augmentation, the notion of flipping a keypoint is dependent on the data representation, and you should probably adapt references/detection/transforms.py for your new keypoint representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "import xml.etree.ElementTree as ET\n",
    "from torch.utils.data import Dataset \n",
    "\n",
    "class CustomImageTensorDataset(Dataset):\n",
    "    def __init__(self, root, transforms=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        #    data (Tensor): A tensor containing the data e.g. images\n",
    "        #    targets (Tensor): A tensor containing all the labels\n",
    "        #    transform (callable, optional): Optional transform to be applied\n",
    "        #        on a sample.\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        # load all image files, sorting them to\n",
    "        # ensure that they are aligned\n",
    "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"JPGImages\"))))\n",
    "        self.boxes = list(sorted(os.listdir(os.path.join(root, \"Boxes\"))))\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # load images and boxes\n",
    "        img_path = os.path.join(self.root, \"JPGImages\", self.imgs[idx])\n",
    "        box_path = os.path.join(self.root, \"Boxes\", self.boxes[idx])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        tree = ET.parse(box_path)\n",
    "        treeroot = tree.getroot()\n",
    "        boxes = []\n",
    "        one_box = []\n",
    "        for i in range(6, len(treeroot)):\n",
    "            boxes.append([int(treeroot[i][4][j].text) for j in range(4)])    \n",
    "        \n",
    "        # convert everything into a torch.Tensor\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        \n",
    "        # there is only one class\n",
    "        labels = torch.ones((len(boxes),), dtype=torch.int64)\n",
    "        \n",
    "        image_id = torch.tensor([idx])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        \n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.zeros((len(boxes),), dtype=torch.int64)\n",
    "        \n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)        \n",
    "        \n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformations + data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'vision/references/detection')\n",
    "\n",
    "import transforms as T\n",
    "import utils\n",
    "\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.1255, 0.1255, 0.1255,  ..., 0.8000, 0.8078, 0.8196],\n",
      "         [0.1255, 0.1255, 0.1255,  ..., 0.8039, 0.8157, 0.8235],\n",
      "         [0.1255, 0.1255, 0.1216,  ..., 0.8157, 0.8275, 0.8314],\n",
      "         ...,\n",
      "         [0.0902, 0.0863, 0.0863,  ..., 0.0980, 0.0980, 0.1765],\n",
      "         [0.0902, 0.0902, 0.0863,  ..., 0.1098, 0.1020, 0.1765],\n",
      "         [0.0941, 0.0902, 0.0863,  ..., 0.1176, 0.1020, 0.1569]],\n",
      "\n",
      "        [[0.1294, 0.1294, 0.1294,  ..., 0.8627, 0.8784, 0.8902],\n",
      "         [0.1294, 0.1294, 0.1294,  ..., 0.8667, 0.8863, 0.8941],\n",
      "         [0.1294, 0.1294, 0.1255,  ..., 0.8784, 0.8980, 0.9020],\n",
      "         ...,\n",
      "         [0.0902, 0.0863, 0.0863,  ..., 0.0980, 0.0980, 0.1843],\n",
      "         [0.0902, 0.0902, 0.0863,  ..., 0.1098, 0.1020, 0.1843],\n",
      "         [0.0941, 0.0902, 0.0863,  ..., 0.1176, 0.1020, 0.1647]],\n",
      "\n",
      "        [[0.1059, 0.1059, 0.1059,  ..., 0.9529, 0.9647, 0.9765],\n",
      "         [0.1059, 0.1059, 0.1059,  ..., 0.9569, 0.9725, 0.9804],\n",
      "         [0.1059, 0.1059, 0.1020,  ..., 0.9765, 0.9843, 0.9882],\n",
      "         ...,\n",
      "         [0.0902, 0.0863, 0.0863,  ..., 0.0980, 0.0980, 0.1804],\n",
      "         [0.0902, 0.0902, 0.0863,  ..., 0.1098, 0.1020, 0.1804],\n",
      "         [0.0941, 0.0902, 0.0863,  ..., 0.1176, 0.1020, 0.1608]]])\n",
      "{'boxes': tensor([[279., 222., 313., 276.],\n",
      "        [361., 226., 396., 360.],\n",
      "        [399., 231., 421., 326.]]), 'labels': tensor([1, 1, 1]), 'image_id': tensor([0]), 'area': tensor([1836., 4690., 2090.]), 'iscrowd': tensor([0, 0, 0])}\n"
     ]
    }
   ],
   "source": [
    "dataset_train = CustomImageTensorDataset('custom_dataset', get_transform(train=True))\n",
    "dataset_test = CustomImageTensorDataset('custom_dataset', get_transform(train=False))\n",
    "\n",
    "# print(dataset_test[0])\n",
    "# print(len(dataset_test))\n",
    "\n",
    "\n",
    "print(dataset_test[0][0])\n",
    "print(dataset_test[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset in train and test set\n",
    "torch.manual_seed(1)\n",
    "indices = torch.randperm(len(dataset_train)).tolist()\n",
    "dataset_train = torch.utils.data.Subset(dataset_train, indices[:-30])\n",
    "dataset_test = torch.utils.data.Subset(dataset_test, indices[-30:])\n",
    "\n",
    "# define training and validation data loaders\n",
    "data_loader_train = torch.utils.data.DataLoader(\n",
    "        dataset_train, batch_size=2, shuffle=True, num_workers=0,\n",
    "        collate_fn=utils.collate_fn)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "        dataset_test, batch_size=1, shuffle=False, num_workers=0,\n",
    "        collate_fn=utils.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 360, 640])\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "print(dataset_test[5][0].shape)\n",
    "# print(dataset_test[0][0])\n",
    "print(len(dataset_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning from a pretrained model (Faster R-CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "# load a model pre-trained on COCO\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "# replace the classifier with a new one, that has\n",
    "# num_classes which is user-defined\n",
    "num_classes = 2  # 1 class (person) + background\n",
    "# get number of input features for the classifier\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "# replace the pre-trained head with a new one\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing the training and check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from engine import train_one_epoch, evaluate\n",
    "import utils\n",
    "import transforms as T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "lr = 5e-3\n",
    "momentum = 0.9\n",
    "# batch_size = 1\n",
    "# test_batch_size = 1000\n",
    "n_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# our dataset has two classes only - background and person\n",
    "num_classes = 2\n",
    "\n",
    "# move model to the right device\n",
    "model.to(device)\n",
    "\n",
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005,\n",
    "                                momentum=0.9, weight_decay=0.0005)\n",
    "# and a learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                                   step_size=3,\n",
    "                                                   gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [ 0/60]  eta: 0:59:13  lr: 0.000090  loss: 1.1860 (1.1860)  loss_classifier: 0.9940 (0.9940)  loss_box_reg: 0.0240 (0.0240)  loss_objectness: 0.1359 (0.1359)  loss_rpn_box_reg: 0.0321 (0.0321)  time: 59.2318  data: 0.0848  max mem: 0\n",
      "Epoch: [0]  [10/60]  eta: 0:37:16  lr: 0.000936  loss: 0.5550 (0.7035)  loss_classifier: 0.4619 (0.5303)  loss_box_reg: 0.0870 (0.0916)  loss_objectness: 0.0468 (0.0602)  loss_rpn_box_reg: 0.0227 (0.0214)  time: 44.7211  data: 0.0701  max mem: 0\n",
      "Epoch: [0]  [20/60]  eta: 0:28:35  lr: 0.001783  loss: 0.3060 (0.4996)  loss_classifier: 0.1907 (0.3504)  loss_box_reg: 0.0744 (0.0838)  loss_objectness: 0.0352 (0.0484)  loss_rpn_box_reg: 0.0131 (0.0170)  time: 42.0635  data: 0.0709  max mem: 0\n",
      "Epoch: [0]  [30/60]  eta: 0:21:28  lr: 0.002629  loss: 0.2889 (0.4617)  loss_classifier: 0.1418 (0.2993)  loss_box_reg: 0.0840 (0.1065)  loss_objectness: 0.0292 (0.0405)  loss_rpn_box_reg: 0.0096 (0.0154)  time: 41.9861  data: 0.0746  max mem: 0\n",
      "Epoch: [0]  [40/60]  eta: 0:15:27  lr: 0.003476  loss: 0.3332 (0.4192)  loss_classifier: 0.1341 (0.2541)  loss_box_reg: 0.1320 (0.1150)  loss_objectness: 0.0180 (0.0355)  loss_rpn_box_reg: 0.0097 (0.0147)  time: 50.0579  data: 0.0835  max mem: 0\n",
      "Epoch: [0]  [50/60]  eta: 0:07:51  lr: 0.004323  loss: 0.2220 (0.3871)  loss_classifier: 0.0965 (0.2230)  loss_box_reg: 0.1226 (0.1171)  loss_objectness: 0.0075 (0.0323)  loss_rpn_box_reg: 0.0095 (0.0147)  time: 53.7050  data: 0.0820  max mem: 0\n",
      "Epoch: [0]  [59/60]  eta: 0:00:46  lr: 0.005000  loss: 0.2053 (0.3661)  loss_classifier: 0.0749 (0.2035)  loss_box_reg: 0.1108 (0.1190)  loss_objectness: 0.0051 (0.0287)  loss_rpn_box_reg: 0.0103 (0.0149)  time: 48.8480  data: 0.0745  max mem: 0\n",
      "Epoch: [0] Total time: 0:46:52 (46.8776 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/30]  eta: 0:09:16  model_time: 13.9729 (13.9729)  evaluator_time: 0.0150 (0.0150)  time: 18.5591  data: 0.0152  max mem: 0\n",
      "Test:  [29/30]  eta: 0:00:14  model_time: 14.4473 (14.4140)  evaluator_time: 0.0020 (0.0049)  time: 14.5877  data: 0.0120  max mem: 0\n",
      "Test: Total time: 0:07:19 (14.6573 s / it)\n",
      "Averaged stats: model_time: 14.4473 (14.4140)  evaluator_time: 0.0020 (0.0049)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.335\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.719\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.303\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.078\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.365\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.535\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.255\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.430\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.452\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.475\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.600\n",
      "Epoch: [1]  [ 0/60]  eta: 0:53:05  lr: 0.005000  loss: 0.2866 (0.2866)  loss_classifier: 0.1199 (0.1199)  loss_box_reg: 0.0929 (0.0929)  loss_objectness: 0.0481 (0.0481)  loss_rpn_box_reg: 0.0257 (0.0257)  time: 53.0904  data: 0.0469  max mem: 0\n",
      "Epoch: [1]  [10/60]  eta: 0:38:35  lr: 0.005000  loss: 0.1398 (0.1634)  loss_classifier: 0.0570 (0.0683)  loss_box_reg: 0.0687 (0.0695)  loss_objectness: 0.0029 (0.0120)  loss_rpn_box_reg: 0.0125 (0.0136)  time: 46.3096  data: 0.0563  max mem: 0\n",
      "Epoch: [1]  [20/60]  eta: 0:29:21  lr: 0.005000  loss: 0.1336 (0.1493)  loss_classifier: 0.0570 (0.0663)  loss_box_reg: 0.0528 (0.0619)  loss_objectness: 0.0029 (0.0089)  loss_rpn_box_reg: 0.0094 (0.0123)  time: 43.5875  data: 0.0533  max mem: 0\n",
      "Epoch: [1]  [30/60]  eta: 0:21:40  lr: 0.005000  loss: 0.1545 (0.1704)  loss_classifier: 0.0664 (0.0737)  loss_box_reg: 0.0691 (0.0708)  loss_objectness: 0.0035 (0.0122)  loss_rpn_box_reg: 0.0110 (0.0137)  time: 41.7117  data: 0.0549  max mem: 0\n",
      "Epoch: [1]  [40/60]  eta: 0:14:18  lr: 0.005000  loss: 0.1755 (0.1681)  loss_classifier: 0.0837 (0.0735)  loss_box_reg: 0.0598 (0.0686)  loss_objectness: 0.0044 (0.0126)  loss_rpn_box_reg: 0.0114 (0.0134)  time: 41.7209  data: 0.0568  max mem: 0\n",
      "Epoch: [1]  [50/60]  eta: 0:07:06  lr: 0.005000  loss: 0.1355 (0.1656)  loss_classifier: 0.0514 (0.0723)  loss_box_reg: 0.0532 (0.0685)  loss_objectness: 0.0038 (0.0112)  loss_rpn_box_reg: 0.0124 (0.0137)  time: 41.5161  data: 0.0562  max mem: 0\n",
      "Epoch: [1]  [59/60]  eta: 0:00:42  lr: 0.005000  loss: 0.1355 (0.1659)  loss_classifier: 0.0514 (0.0732)  loss_box_reg: 0.0546 (0.0695)  loss_objectness: 0.0030 (0.0100)  loss_rpn_box_reg: 0.0124 (0.0133)  time: 41.3059  data: 0.0565  max mem: 0\n",
      "Epoch: [1] Total time: 0:42:24 (42.4071 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/30]  eta: 0:07:08  model_time: 14.2439 (14.2439)  evaluator_time: 0.0100 (0.0100)  time: 14.2758  data: 0.0126  max mem: 0\n",
      "Test:  [29/30]  eta: 0:00:13  model_time: 13.6845 (13.7033)  evaluator_time: 0.0020 (0.0034)  time: 13.8115  data: 0.0118  max mem: 0\n",
      "Test: Total time: 0:06:54 (13.8149 s / it)\n",
      "Averaged stats: model_time: 13.6845 (13.7033)  evaluator_time: 0.0020 (0.0034)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.501\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.831\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.517\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.166\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.527\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.750\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.334\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.605\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.614\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.383\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.635\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.800\n",
      "Epoch: [2]  [ 0/60]  eta: 0:41:24  lr: 0.005000  loss: 0.1109 (0.1109)  loss_classifier: 0.0686 (0.0686)  loss_box_reg: 0.0310 (0.0310)  loss_objectness: 0.0028 (0.0028)  loss_rpn_box_reg: 0.0086 (0.0086)  time: 41.4163  data: 0.0519  max mem: 0\n",
      "Epoch: [2]  [10/60]  eta: 0:34:30  lr: 0.005000  loss: 0.1125 (0.1235)  loss_classifier: 0.0659 (0.0594)  loss_box_reg: 0.0369 (0.0512)  loss_objectness: 0.0019 (0.0021)  loss_rpn_box_reg: 0.0116 (0.0108)  time: 41.4008  data: 0.0425  max mem: 0\n",
      "Epoch: [2]  [20/60]  eta: 0:27:37  lr: 0.005000  loss: 0.1125 (0.1391)  loss_classifier: 0.0580 (0.0632)  loss_box_reg: 0.0446 (0.0608)  loss_objectness: 0.0012 (0.0028)  loss_rpn_box_reg: 0.0116 (0.0124)  time: 41.4474  data: 0.0401  max mem: 0\n",
      "Epoch: [2]  [30/60]  eta: 0:20:50  lr: 0.005000  loss: 0.0824 (0.1241)  loss_classifier: 0.0398 (0.0572)  loss_box_reg: 0.0373 (0.0534)  loss_objectness: 0.0009 (0.0023)  loss_rpn_box_reg: 0.0095 (0.0111)  time: 41.8269  data: 0.0430  max mem: 0\n",
      "Epoch: [2]  [40/60]  eta: 0:13:56  lr: 0.005000  loss: 0.0765 (0.1192)  loss_classifier: 0.0325 (0.0548)  loss_box_reg: 0.0373 (0.0499)  loss_objectness: 0.0010 (0.0033)  loss_rpn_box_reg: 0.0074 (0.0111)  time: 42.2162  data: 0.0515  max mem: 0\n",
      "Epoch: [2]  [50/60]  eta: 0:06:57  lr: 0.005000  loss: 0.0891 (0.1205)  loss_classifier: 0.0328 (0.0552)  loss_box_reg: 0.0411 (0.0515)  loss_objectness: 0.0012 (0.0031)  loss_rpn_box_reg: 0.0081 (0.0108)  time: 41.8475  data: 0.0563  max mem: 0\n",
      "Epoch: [2]  [59/60]  eta: 0:00:41  lr: 0.005000  loss: 0.1074 (0.1249)  loss_classifier: 0.0450 (0.0573)  loss_box_reg: 0.0421 (0.0536)  loss_objectness: 0.0014 (0.0030)  loss_rpn_box_reg: 0.0082 (0.0110)  time: 41.3886  data: 0.0588  max mem: 0\n",
      "Epoch: [2] Total time: 0:41:41 (41.6913 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/30]  eta: 0:06:57  model_time: 13.8944 (13.8944)  evaluator_time: 0.0030 (0.0030)  time: 13.9084  data: 0.0110  max mem: 0\n",
      "Test:  [29/30]  eta: 0:00:13  model_time: 13.5489 (13.6257)  evaluator_time: 0.0010 (0.0018)  time: 13.6434  data: 0.0114  max mem: 0\n",
      "Test: Total time: 0:06:51 (13.7049 s / it)\n",
      "Averaged stats: model_time: 13.5489 (13.6257)  evaluator_time: 0.0010 (0.0018)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.511\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.854\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.575\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.250\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.529\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.825\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.346\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.573\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.575\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.598\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.850\n",
      "Epoch: [3]  [ 0/60]  eta: 0:41:20  lr: 0.000500  loss: 0.0682 (0.0682)  loss_classifier: 0.0329 (0.0329)  loss_box_reg: 0.0266 (0.0266)  loss_objectness: 0.0040 (0.0040)  loss_rpn_box_reg: 0.0047 (0.0047)  time: 41.3357  data: 0.0648  max mem: 0\n",
      "Epoch: [3]  [10/60]  eta: 0:34:33  lr: 0.000500  loss: 0.0665 (0.0793)  loss_classifier: 0.0324 (0.0362)  loss_box_reg: 0.0294 (0.0329)  loss_objectness: 0.0012 (0.0018)  loss_rpn_box_reg: 0.0069 (0.0085)  time: 41.4774  data: 0.0465  max mem: 0\n",
      "Epoch: [3]  [20/60]  eta: 0:28:50  lr: 0.000500  loss: 0.0659 (0.0817)  loss_classifier: 0.0320 (0.0377)  loss_box_reg: 0.0294 (0.0331)  loss_objectness: 0.0012 (0.0017)  loss_rpn_box_reg: 0.0077 (0.0091)  time: 43.3524  data: 0.0478  max mem: 0\n",
      "Epoch: [3]  [30/60]  eta: 0:22:14  lr: 0.000500  loss: 0.0799 (0.0933)  loss_classifier: 0.0320 (0.0427)  loss_box_reg: 0.0329 (0.0387)  loss_objectness: 0.0019 (0.0025)  loss_rpn_box_reg: 0.0083 (0.0094)  time: 46.1426  data: 0.0474  max mem: 0\n",
      "Epoch: [3]  [40/60]  eta: 0:15:02  lr: 0.000500  loss: 0.0653 (0.0904)  loss_classifier: 0.0303 (0.0411)  loss_box_reg: 0.0310 (0.0383)  loss_objectness: 0.0010 (0.0021)  loss_rpn_box_reg: 0.0080 (0.0089)  time: 47.0732  data: 0.0435  max mem: 0\n",
      "Epoch: [3]  [50/60]  eta: 0:07:35  lr: 0.000500  loss: 0.0646 (0.0907)  loss_classifier: 0.0337 (0.0416)  loss_box_reg: 0.0257 (0.0382)  loss_objectness: 0.0008 (0.0022)  loss_rpn_box_reg: 0.0068 (0.0086)  time: 47.1623  data: 0.0475  max mem: 0\n",
      "Epoch: [3]  [59/60]  eta: 0:00:46  lr: 0.000500  loss: 0.0985 (0.0943)  loss_classifier: 0.0564 (0.0437)  loss_box_reg: 0.0379 (0.0389)  loss_objectness: 0.0013 (0.0023)  loss_rpn_box_reg: 0.0081 (0.0095)  time: 48.3706  data: 0.0576  max mem: 0\n",
      "Epoch: [3] Total time: 0:46:05 (46.0862 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/30]  eta: 0:07:09  model_time: 14.2674 (14.2674)  evaluator_time: 0.0090 (0.0090)  time: 14.3014  data: 0.0130  max mem: 0\n",
      "Test:  [29/30]  eta: 0:00:14  model_time: 14.2541 (14.3785)  evaluator_time: 0.0010 (0.0023)  time: 14.5598  data: 0.0131  max mem: 0\n",
      "Test: Total time: 0:07:14 (14.4848 s / it)\n",
      "Averaged stats: model_time: 14.2541 (14.3785)  evaluator_time: 0.0010 (0.0023)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.571\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.876\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.653\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.247\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.599\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.825\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.379\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.618\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.620\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.644\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.850\n",
      "Epoch: [4]  [ 0/60]  eta: 0:43:50  lr: 0.000500  loss: 0.0299 (0.0299)  loss_classifier: 0.0194 (0.0194)  loss_box_reg: 0.0066 (0.0066)  loss_objectness: 0.0006 (0.0006)  loss_rpn_box_reg: 0.0034 (0.0034)  time: 43.8423  data: 0.0701  max mem: 0\n",
      "Epoch: [4]  [10/60]  eta: 0:38:23  lr: 0.000500  loss: 0.0517 (0.0620)  loss_classifier: 0.0249 (0.0312)  loss_box_reg: 0.0224 (0.0241)  loss_objectness: 0.0007 (0.0007)  loss_rpn_box_reg: 0.0053 (0.0059)  time: 46.0762  data: 0.0574  max mem: 0\n",
      "Epoch: [4]  [20/60]  eta: 0:30:35  lr: 0.000500  loss: 0.0518 (0.0691)  loss_classifier: 0.0249 (0.0314)  loss_box_reg: 0.0224 (0.0294)  loss_objectness: 0.0008 (0.0010)  loss_rpn_box_reg: 0.0070 (0.0073)  time: 46.0017  data: 0.0535  max mem: 0\n",
      "Epoch: [4]  [30/60]  eta: 0:23:03  lr: 0.000500  loss: 0.0589 (0.0707)  loss_classifier: 0.0340 (0.0328)  loss_box_reg: 0.0288 (0.0296)  loss_objectness: 0.0009 (0.0010)  loss_rpn_box_reg: 0.0068 (0.0072)  time: 46.1512  data: 0.0569  max mem: 0\n",
      "Epoch: [4]  [40/60]  eta: 0:15:28  lr: 0.000500  loss: 0.0692 (0.0752)  loss_classifier: 0.0355 (0.0348)  loss_box_reg: 0.0285 (0.0316)  loss_objectness: 0.0011 (0.0013)  loss_rpn_box_reg: 0.0058 (0.0075)  time: 46.9274  data: 0.0597  max mem: 0\n",
      "Epoch: [4]  [50/60]  eta: 0:07:45  lr: 0.000500  loss: 0.0667 (0.0840)  loss_classifier: 0.0368 (0.0401)  loss_box_reg: 0.0272 (0.0348)  loss_objectness: 0.0013 (0.0014)  loss_rpn_box_reg: 0.0077 (0.0077)  time: 47.1328  data: 0.0592  max mem: 0\n",
      "Epoch: [4]  [59/60]  eta: 0:00:46  lr: 0.000500  loss: 0.0640 (0.0841)  loss_classifier: 0.0356 (0.0395)  loss_box_reg: 0.0248 (0.0351)  loss_objectness: 0.0010 (0.0016)  loss_rpn_box_reg: 0.0085 (0.0080)  time: 46.0438  data: 0.0618  max mem: 0\n",
      "Epoch: [4] Total time: 0:46:15 (46.2605 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/30]  eta: 0:07:23  model_time: 14.5605 (14.5605)  evaluator_time: 0.0080 (0.0080)  time: 14.7849  data: 0.0170  max mem: 0\n",
      "Test:  [29/30]  eta: 0:00:14  model_time: 14.5733 (14.7706)  evaluator_time: 0.0020 (0.0024)  time: 14.7177  data: 0.0130  max mem: 0\n",
      "Test: Total time: 0:07:26 (14.8800 s / it)\n",
      "Averaged stats: model_time: 14.5733 (14.7706)  evaluator_time: 0.0020 (0.0024)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.567\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.872\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.675\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.244\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.594\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.825\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.366\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.614\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.614\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.283\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.646\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.850\n",
      "Epoch: [5]  [ 0/60]  eta: 0:44:42  lr: 0.000500  loss: 0.0401 (0.0401)  loss_classifier: 0.0224 (0.0224)  loss_box_reg: 0.0137 (0.0137)  loss_objectness: 0.0015 (0.0015)  loss_rpn_box_reg: 0.0025 (0.0025)  time: 44.7045  data: 0.0549  max mem: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5]  [10/60]  eta: 0:39:15  lr: 0.000500  loss: 0.0435 (0.0578)  loss_classifier: 0.0224 (0.0270)  loss_box_reg: 0.0158 (0.0231)  loss_objectness: 0.0009 (0.0012)  loss_rpn_box_reg: 0.0056 (0.0064)  time: 47.1014  data: 0.0463  max mem: 0\n",
      "Epoch: [5]  [20/60]  eta: 0:30:59  lr: 0.000500  loss: 0.0436 (0.0670)  loss_classifier: 0.0226 (0.0313)  loss_box_reg: 0.0158 (0.0264)  loss_objectness: 0.0005 (0.0020)  loss_rpn_box_reg: 0.0057 (0.0072)  time: 46.5787  data: 0.0456  max mem: 0\n",
      "Epoch: [5]  [30/60]  eta: 0:23:24  lr: 0.000500  loss: 0.0716 (0.0758)  loss_classifier: 0.0319 (0.0347)  loss_box_reg: 0.0246 (0.0313)  loss_objectness: 0.0005 (0.0017)  loss_rpn_box_reg: 0.0084 (0.0081)  time: 46.6390  data: 0.0448  max mem: 0\n",
      "Epoch: [5]  [40/60]  eta: 0:15:30  lr: 0.000500  loss: 0.0699 (0.0744)  loss_classifier: 0.0365 (0.0351)  loss_box_reg: 0.0250 (0.0302)  loss_objectness: 0.0006 (0.0016)  loss_rpn_box_reg: 0.0063 (0.0075)  time: 46.5373  data: 0.0542  max mem: 0\n",
      "Epoch: [5]  [50/60]  eta: 0:07:44  lr: 0.000500  loss: 0.0687 (0.0776)  loss_classifier: 0.0340 (0.0370)  loss_box_reg: 0.0250 (0.0317)  loss_objectness: 0.0007 (0.0016)  loss_rpn_box_reg: 0.0048 (0.0073)  time: 46.0136  data: 0.0696  max mem: 0\n",
      "Epoch: [5]  [59/60]  eta: 0:00:47  lr: 0.000500  loss: 0.0664 (0.0775)  loss_classifier: 0.0324 (0.0370)  loss_box_reg: 0.0250 (0.0318)  loss_objectness: 0.0004 (0.0014)  loss_rpn_box_reg: 0.0048 (0.0073)  time: 49.3094  data: 0.0693  max mem: 0\n",
      "Epoch: [5] Total time: 0:47:31 (47.5241 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/30]  eta: 0:09:29  model_time: 18.9367 (18.9367)  evaluator_time: 0.0080 (0.0080)  time: 18.9686  data: 0.0159  max mem: 0\n",
      "Test:  [29/30]  eta: 0:00:14  model_time: 14.2442 (14.5628)  evaluator_time: 0.0020 (0.0025)  time: 14.3903  data: 0.0129  max mem: 0\n",
      "Test: Total time: 0:07:19 (14.6349 s / it)\n",
      "Averaged stats: model_time: 14.2442 (14.5628)  evaluator_time: 0.0020 (0.0025)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.568\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.874\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.653\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.248\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.595\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.825\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.371\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.614\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.614\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.283\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.646\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.850\n",
      "Epoch: [6]  [ 0/60]  eta: 0:46:48  lr: 0.000050  loss: 0.0578 (0.0578)  loss_classifier: 0.0266 (0.0266)  loss_box_reg: 0.0270 (0.0270)  loss_objectness: 0.0003 (0.0003)  loss_rpn_box_reg: 0.0039 (0.0039)  time: 46.8065  data: 0.0499  max mem: 0\n",
      "Epoch: [6]  [10/60]  eta: 0:48:26  lr: 0.000050  loss: 0.0548 (0.0573)  loss_classifier: 0.0266 (0.0290)  loss_box_reg: 0.0215 (0.0221)  loss_objectness: 0.0002 (0.0011)  loss_rpn_box_reg: 0.0049 (0.0050)  time: 58.1326  data: 0.0611  max mem: 0\n",
      "Epoch: [6]  [20/60]  eta: 0:43:26  lr: 0.000050  loss: 0.0465 (0.0591)  loss_classifier: 0.0263 (0.0299)  loss_box_reg: 0.0187 (0.0228)  loss_objectness: 0.0002 (0.0011)  loss_rpn_box_reg: 0.0046 (0.0053)  time: 66.0685  data: 0.0778  max mem: 0\n",
      "Epoch: [6]  [30/60]  eta: 0:34:00  lr: 0.000050  loss: 0.0455 (0.0588)  loss_classifier: 0.0227 (0.0293)  loss_box_reg: 0.0161 (0.0227)  loss_objectness: 0.0003 (0.0011)  loss_rpn_box_reg: 0.0037 (0.0057)  time: 73.4272  data: 0.0911  max mem: 0\n",
      "Epoch: [6]  [40/60]  eta: 0:23:30  lr: 0.000050  loss: 0.0628 (0.0712)  loss_classifier: 0.0339 (0.0354)  loss_box_reg: 0.0210 (0.0278)  loss_objectness: 0.0007 (0.0013)  loss_rpn_box_reg: 0.0064 (0.0068)  time: 76.1906  data: 0.0982  max mem: 0\n",
      "Epoch: [6]  [50/60]  eta: 0:12:00  lr: 0.000050  loss: 0.0744 (0.0744)  loss_classifier: 0.0461 (0.0368)  loss_box_reg: 0.0292 (0.0293)  loss_objectness: 0.0006 (0.0013)  loss_rpn_box_reg: 0.0077 (0.0069)  time: 78.2099  data: 0.1139  max mem: 0\n",
      "Epoch: [6]  [59/60]  eta: 0:01:13  lr: 0.000050  loss: 0.0628 (0.0731)  loss_classifier: 0.0310 (0.0356)  loss_box_reg: 0.0229 (0.0294)  loss_objectness: 0.0004 (0.0012)  loss_rpn_box_reg: 0.0058 (0.0069)  time: 78.5446  data: 0.1195  max mem: 0\n",
      "Epoch: [6] Total time: 1:13:03 (73.0650 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/30]  eta: 0:14:58  model_time: 29.6149 (29.6149)  evaluator_time: 0.0100 (0.0100)  time: 29.9381  data: 0.0409  max mem: 0\n",
      "Test:  [29/30]  eta: 0:00:24  model_time: 13.9048 (24.1922)  evaluator_time: 0.0020 (0.0040)  time: 21.0241  data: 0.0172  max mem: 0\n",
      "Test: Total time: 0:12:08 (24.2868 s / it)\n",
      "Averaged stats: model_time: 13.9048 (24.1922)  evaluator_time: 0.0020 (0.0040)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.570\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.875\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.674\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.271\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.596\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.825\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.371\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.616\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.616\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.646\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.850\n",
      "Epoch: [7]  [ 0/60]  eta: 0:42:36  lr: 0.000050  loss: 0.0488 (0.0488)  loss_classifier: 0.0289 (0.0289)  loss_box_reg: 0.0149 (0.0149)  loss_objectness: 0.0003 (0.0003)  loss_rpn_box_reg: 0.0047 (0.0047)  time: 42.6094  data: 0.0329  max mem: 0\n",
      "Epoch: [7]  [10/60]  eta: 0:34:43  lr: 0.000050  loss: 0.0448 (0.0614)  loss_classifier: 0.0262 (0.0302)  loss_box_reg: 0.0149 (0.0243)  loss_objectness: 0.0003 (0.0012)  loss_rpn_box_reg: 0.0047 (0.0057)  time: 41.6783  data: 0.0389  max mem: 0\n",
      "Epoch: [7]  [20/60]  eta: 0:27:41  lr: 0.000050  loss: 0.0596 (0.0760)  loss_classifier: 0.0262 (0.0354)  loss_box_reg: 0.0211 (0.0315)  loss_objectness: 0.0003 (0.0011)  loss_rpn_box_reg: 0.0050 (0.0080)  time: 41.4850  data: 0.0398  max mem: 0\n",
      "Epoch: [7]  [30/60]  eta: 0:20:52  lr: 0.000050  loss: 0.0619 (0.0727)  loss_classifier: 0.0256 (0.0345)  loss_box_reg: 0.0185 (0.0296)  loss_objectness: 0.0003 (0.0009)  loss_rpn_box_reg: 0.0071 (0.0076)  time: 41.7692  data: 0.0419  max mem: 0\n",
      "Epoch: [7]  [40/60]  eta: 0:13:57  lr: 0.000050  loss: 0.0447 (0.0684)  loss_classifier: 0.0240 (0.0325)  loss_box_reg: 0.0165 (0.0279)  loss_objectness: 0.0003 (0.0008)  loss_rpn_box_reg: 0.0048 (0.0071)  time: 42.2166  data: 0.0436  max mem: 0\n",
      "Epoch: [7]  [50/60]  eta: 0:06:58  lr: 0.000050  loss: 0.0658 (0.0741)  loss_classifier: 0.0345 (0.0354)  loss_box_reg: 0.0240 (0.0301)  loss_objectness: 0.0005 (0.0009)  loss_rpn_box_reg: 0.0068 (0.0077)  time: 41.9175  data: 0.0436  max mem: 0\n",
      "Epoch: [7]  [59/60]  eta: 0:00:41  lr: 0.000050  loss: 0.0750 (0.0740)  loss_classifier: 0.0377 (0.0353)  loss_box_reg: 0.0282 (0.0304)  loss_objectness: 0.0004 (0.0008)  loss_rpn_box_reg: 0.0074 (0.0074)  time: 41.5433  data: 0.0447  max mem: 0\n",
      "Epoch: [7] Total time: 0:41:46 (41.7767 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/30]  eta: 0:07:15  model_time: 14.4989 (14.4989)  evaluator_time: 0.0030 (0.0030)  time: 14.5138  data: 0.0110  max mem: 0\n",
      "Test:  [29/30]  eta: 0:00:14  model_time: 13.5768 (14.0302)  evaluator_time: 0.0010 (0.0020)  time: 13.6567  data: 0.0119  max mem: 0\n",
      "Test: Total time: 0:07:03 (14.1113 s / it)\n",
      "Averaged stats: model_time: 13.5768 (14.0302)  evaluator_time: 0.0010 (0.0020)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.576\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.871\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.674\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.262\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.602\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.825\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.375\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.623\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.623\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.650\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.850\n",
      "Epoch: [8]  [ 0/60]  eta: 0:41:25  lr: 0.000050  loss: 0.0387 (0.0387)  loss_classifier: 0.0235 (0.0235)  loss_box_reg: 0.0117 (0.0117)  loss_objectness: 0.0001 (0.0001)  loss_rpn_box_reg: 0.0034 (0.0034)  time: 41.4193  data: 0.0449  max mem: 0\n",
      "Epoch: [8]  [10/60]  eta: 0:34:29  lr: 0.000050  loss: 0.0489 (0.0647)  loss_classifier: 0.0300 (0.0321)  loss_box_reg: 0.0159 (0.0248)  loss_objectness: 0.0008 (0.0012)  loss_rpn_box_reg: 0.0046 (0.0066)  time: 41.3854  data: 0.0427  max mem: 0\n",
      "Epoch: [8]  [20/60]  eta: 0:27:36  lr: 0.000050  loss: 0.0703 (0.0785)  loss_classifier: 0.0351 (0.0369)  loss_box_reg: 0.0271 (0.0323)  loss_objectness: 0.0007 (0.0013)  loss_rpn_box_reg: 0.0059 (0.0080)  time: 41.4187  data: 0.0437  max mem: 0\n",
      "Epoch: [8]  [30/60]  eta: 0:20:40  lr: 0.000050  loss: 0.0472 (0.0655)  loss_classifier: 0.0249 (0.0316)  loss_box_reg: 0.0146 (0.0265)  loss_objectness: 0.0003 (0.0010)  loss_rpn_box_reg: 0.0046 (0.0066)  time: 41.3318  data: 0.0452  max mem: 0\n",
      "Epoch: [8]  [40/60]  eta: 0:13:46  lr: 0.000050  loss: 0.0424 (0.0670)  loss_classifier: 0.0183 (0.0317)  loss_box_reg: 0.0122 (0.0273)  loss_objectness: 0.0003 (0.0011)  loss_rpn_box_reg: 0.0042 (0.0068)  time: 41.2401  data: 0.0473  max mem: 0\n",
      "Epoch: [8]  [50/60]  eta: 0:06:53  lr: 0.000050  loss: 0.0561 (0.0692)  loss_classifier: 0.0293 (0.0326)  loss_box_reg: 0.0249 (0.0285)  loss_objectness: 0.0006 (0.0012)  loss_rpn_box_reg: 0.0062 (0.0069)  time: 41.2638  data: 0.0465  max mem: 0\n",
      "Epoch: [8]  [59/60]  eta: 0:00:41  lr: 0.000050  loss: 0.0561 (0.0713)  loss_classifier: 0.0283 (0.0336)  loss_box_reg: 0.0249 (0.0295)  loss_objectness: 0.0006 (0.0012)  loss_rpn_box_reg: 0.0065 (0.0070)  time: 41.6820  data: 0.0449  max mem: 0\n",
      "Epoch: [8] Total time: 0:41:27 (41.4506 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/30]  eta: 0:06:51  model_time: 13.6982 (13.6982)  evaluator_time: 0.0020 (0.0020)  time: 13.7122  data: 0.0110  max mem: 0\n",
      "Test:  [29/30]  eta: 0:00:13  model_time: 13.5937 (13.6325)  evaluator_time: 0.0010 (0.0016)  time: 13.7060  data: 0.0120  max mem: 0\n",
      "Test: Total time: 0:06:51 (13.7233 s / it)\n",
      "Averaged stats: model_time: 13.5937 (13.6325)  evaluator_time: 0.0010 (0.0016)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.578\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.871\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.674\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.262\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.604\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.825\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.375\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.625\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.625\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.652\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.850\n",
      "Epoch: [9]  [ 0/60]  eta: 0:40:06  lr: 0.000005  loss: 0.0483 (0.0483)  loss_classifier: 0.0271 (0.0271)  loss_box_reg: 0.0181 (0.0181)  loss_objectness: 0.0001 (0.0001)  loss_rpn_box_reg: 0.0031 (0.0031)  time: 40.1098  data: 0.0519  max mem: 0\n",
      "Epoch: [9]  [10/60]  eta: 0:34:19  lr: 0.000005  loss: 0.0561 (0.0571)  loss_classifier: 0.0283 (0.0300)  loss_box_reg: 0.0204 (0.0217)  loss_objectness: 0.0002 (0.0003)  loss_rpn_box_reg: 0.0054 (0.0052)  time: 41.1939  data: 0.0379  max mem: 0\n",
      "Epoch: [9]  [20/60]  eta: 0:27:31  lr: 0.000005  loss: 0.0543 (0.0638)  loss_classifier: 0.0279 (0.0313)  loss_box_reg: 0.0204 (0.0258)  loss_objectness: 0.0004 (0.0008)  loss_rpn_box_reg: 0.0058 (0.0060)  time: 41.3398  data: 0.0399  max mem: 0\n",
      "Epoch: [9]  [30/60]  eta: 0:20:39  lr: 0.000005  loss: 0.0586 (0.0715)  loss_classifier: 0.0283 (0.0347)  loss_box_reg: 0.0237 (0.0295)  loss_objectness: 0.0007 (0.0009)  loss_rpn_box_reg: 0.0057 (0.0064)  time: 41.3882  data: 0.0457  max mem: 0\n",
      "Epoch: [9]  [40/60]  eta: 0:13:46  lr: 0.000005  loss: 0.0965 (0.0791)  loss_classifier: 0.0464 (0.0375)  loss_box_reg: 0.0388 (0.0335)  loss_objectness: 0.0004 (0.0009)  loss_rpn_box_reg: 0.0062 (0.0073)  time: 41.3646  data: 0.0469  max mem: 0\n",
      "Epoch: [9]  [50/60]  eta: 0:06:52  lr: 0.000005  loss: 0.0597 (0.0762)  loss_classifier: 0.0285 (0.0357)  loss_box_reg: 0.0222 (0.0323)  loss_objectness: 0.0004 (0.0010)  loss_rpn_box_reg: 0.0050 (0.0071)  time: 41.2513  data: 0.0444  max mem: 0\n",
      "Epoch: [9]  [59/60]  eta: 0:00:41  lr: 0.000005  loss: 0.0543 (0.0751)  loss_classifier: 0.0276 (0.0352)  loss_box_reg: 0.0202 (0.0314)  loss_objectness: 0.0004 (0.0012)  loss_rpn_box_reg: 0.0049 (0.0072)  time: 41.2787  data: 0.0451  max mem: 0\n",
      "Epoch: [9] Total time: 0:41:18 (41.3106 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [ 0/30]  eta: 0:06:45  model_time: 13.5099 (13.5099)  evaluator_time: 0.0020 (0.0020)  time: 13.5219  data: 0.0100  max mem: 0\n",
      "Test:  [29/30]  eta: 0:00:13  model_time: 13.6743 (13.8429)  evaluator_time: 0.0010 (0.0017)  time: 13.9506  data: 0.0123  max mem: 0\n",
      "Test: Total time: 0:06:57 (13.9279 s / it)\n",
      "Averaged stats: model_time: 13.6743 (13.8429)  evaluator_time: 0.0010 (0.0017)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.578\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.871\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.674\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.262\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.604\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.825\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.375\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.625\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.625\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.652\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.850\n"
     ]
    }
   ],
   "source": [
    "# let's train it for 10 epochs\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # train for one epoch, printing every 10 iterations\n",
    "    train_one_epoch(model, optimizer, data_loader_train, device, epoch, print_freq=10)\n",
    "    # update the learning rate\n",
    "    lr_scheduler.step()\n",
    "    # evaluate on the test dataset\n",
    "    evaluate(model, data_loader_test, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_name = 'faster-r-cnn-resnet50-fpn-finetuning.pt'\n",
    "path = F\"custom_dataset/{model_save_name}\" \n",
    "torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fig0_13.30.00.jpg', 'fig10000_13.20.00.jpg', 'fig1000_13.30.00.jpg', 'fig10050_13.20.00.jpg', 'fig100_03.00.00.jpg', 'fig10100_13.20.00.jpg', 'fig10150_13.20.00.jpg', 'fig1016_13.30.00.jpg', 'fig10200_13.20.00.jpg', 'fig10250_13.20.00.jpg', 'fig10300_13.20.00.jpg', 'fig10350_13.20.00.jpg', 'fig10400_13.20.00.jpg', 'fig10450_13.20.00.jpg', 'fig10500_13.20.00.jpg', 'fig10550_13.20.00.jpg', 'fig10600_13.20.00.jpg', 'fig10650_13.20.00.jpg', 'fig10700_13.30.00.jpg', 'fig10850_13.20.00.jpg', 'fig10900_13.20.00.jpg', 'fig11000_03.00.00.jpg', 'fig1100_13.30.00.jpg', 'fig11050_13.20.00.jpg', 'fig11100_13.20.00.jpg', 'fig11150_13.20.00.jpg', 'fig11200_13.20.00.jpg', 'fig11250_13.20.00.jpg', 'fig11300_13.20.00.jpg', 'fig11350_13.20.00.jpg', 'fig11400_13.20.00.jpg', 'fig11450_13.20.00.jpg', 'fig11500_13.20.00.jpg', 'fig11550_13.20.00.jpg', 'fig11600_03.00.00.jpg', 'fig11600_13.20.00.jpg', 'fig11650_13.20.00.jpg', 'fig11700_13.20.00.jpg', 'fig11750_13.20.00.jpg', 'fig11800_13.20.00.jpg', 'fig11850_13.20.00.jpg', 'fig11900_03.00.00.jpg', 'fig12200_03.00.00.jpg', 'fig12200_13.20.00.jpg', 'fig12250_13.20.00.jpg', 'fig12300_13.20.00.jpg', 'fig12600_13.30.00.jpg', 'fig13100_13.20.00.jpg', 'fig13200_03.00.00.jpg', 'fig13200_13.30.00.jpg', 'fig13300_03.00.00.jpg', 'fig13300_13.20.00.jpg', 'fig13350_13.20.00.jpg', 'fig13400_03.00.00.jpg', 'fig13500_03.00.00.jpg', 'fig13600_03.00.00.jpg', 'fig13600_13.30.00.jpg', 'fig13700_03.00.00.jpg', 'fig13800_03.00.00.jpg', 'fig1388_13.30.00.jpg', 'fig13900_03.00.00.jpg', 'fig13900_13.30.00.jpg', 'fig13950_13.20.00.jpg', 'fig14000_03.00.00.jpg', 'fig14000_13.30.00.jpg', 'fig1400_03.00.00.jpg', 'fig14100_03.00.00.jpg', 'fig14200_03.00.00.jpg', 'fig14300_03.00.00.jpg', 'fig14300_13.30.00.jpg', 'fig14400_03.00.00.jpg', 'fig14800_03.00.00.jpg', 'fig14800_13.30.00.jpg', 'fig14850_13.20.00.jpg', 'fig14900_03.00.00.jpg', 'fig14900_13.20.00.jpg', 'fig14950_13.20.00.jpg', 'fig15000_03.00.00.jpg', 'fig15000_13.30.00.jpg', 'fig15050_13.20.00.jpg', 'fig15200_03.00.00.jpg', 'fig15200_13.20.00.jpg', 'fig15250_13.20.00.jpg', 'fig15300_03.00.00.jpg', 'fig15300_13.20.00.jpg', 'fig15400_03.00.00.jpg', 'fig15500_03.00.00.jpg', 'fig15500_13.30.00.jpg', 'fig15700_03.00.00.jpg', 'fig15800_03.00.00.jpg', 'fig15900_03.00.00.jpg', 'fig15_13.30.00.jpg', 'fig16600_03.00.00.jpg', 'fig16700_03.00.00.jpg', 'fig16800_03.00.00.jpg', 'fig16900_03.00.00.jpg', 'fig17000_03.00.00.jpg', 'fig1700_03.00.00.jpg', 'fig17100_03.00.00.jpg', 'fig17200_03.00.00.jpg', 'fig17300_03.00.00.jpg', 'fig17400_03.00.00.jpg', 'fig17500_03.00.00.jpg', 'fig17600_03.00.00.jpg', 'fig17700_03.00.00.jpg', 'fig17800_03.00.00.jpg', 'fig18000_03.00.00.jpg', 'fig1800_13.30.00.jpg', 'fig2000_13.30.00.jpg', 'fig200_03.00.00.jpg', 'fig285_13.30.00.jpg', 'fig300_13.30.00.jpg', 'fig324_13.30.00.jpg', 'fig365_13.30.00.jpg', 'fig400_13.30.00.jpg', 'fig4100_03.00.00.jpg', 'fig4200_03.00.00.jpg', 'fig500_13.30.00.jpg', 'fig5900_13.30.00.jpg', 'fig6000_13.30.00.jpg', 'fig600_13.30.00.jpg', 'fig6900_13.30.00.jpg', 'fig7000_03.00.00.jpg', 'fig7100_13.30.00.jpg', 'fig7400_03.00.00.jpg', 'fig7400_13.30.00.jpg', 'fig779_13.30.00.jpg', 'fig7800_13.30.00.jpg', 'fig7900_13.30.00.jpg', 'fig791_13.30.00.jpg', 'fig8000_13.30.00.jpg', 'fig8100_03.00.00.jpg', 'fig8100_13.30.00.jpg', 'fig8300_13.30.00.jpg', 'fig8400_13.30.00.jpg', 'fig8500_13.30.00.jpg', 'fig8600_13.30.00.jpg', 'fig8700_13.30.00.jpg', 'fig892_13.30.00.jpg', 'fig900_13.30.00.jpg', 'fig9100_13.30.00.jpg', 'fig92_13.30.00.jpg', 'fig9300_13.30.00.jpg', 'fig9400_13.30.00.jpg', 'fig9500_13.30.00.jpg', 'fig9600_13.30.00.jpg', 'fig9850_13.20.00.jpg', 'fig9900_13.20.00.jpg', 'fig9900_13.30.00.jpg', 'fig9950_13.20.00.jpg']\n"
     ]
    }
   ],
   "source": [
    "#note: order of the images, for reference\n",
    "\n",
    "directory = r\"C:\\Users\\lsu543\\OneDrive - Schlumberger\\Documents\\project_video_laura\\custom_dataset\\JPGImages\"\n",
    "list_files = []\n",
    "for filename in list(sorted(os.listdir(directory))):\n",
    "    list_files.append(filename)\n",
    "\n",
    "print(list_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the results (if using the model produced before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pick one image from the test set\n",
    "# img, _ = dataset_test[5]\n",
    "# # put the model in evaluation mode\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     prediction = model([img.to(device)])\n",
    "\n",
    "# print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check the true results (pre-labelled)\n",
    "# img, _ = dataset_test[5]\n",
    "# print(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a model on the current architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform()\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d()\n",
       "      (relu): ReLU(inplace)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d()\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d()\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d()\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign()\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "model_save_name = 'faster-r-cnn-resnet50-fpn-finetuning-dividedby2sizeimage.pt'\n",
    "\n",
    "# load a model pre-trained on COCO\n",
    "model1 = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "# replace the classifier with a new one, that has\n",
    "# num_classes which is user-defined\n",
    "num_classes = 2  # 1 class (person) + background\n",
    "# get number of input features for the classifier\n",
    "in_features = model1.roi_heads.box_predictor.cls_score.in_features\n",
    "# replace the pre-trained head with a new one\n",
    "model1.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "model1.load_state_dict(torch.load(F\"custom_dataset/{model_save_name}\"))\n",
    "model1.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the results (with loaded model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'boxes': tensor([[500.9510, 243.8863, 615.6051, 360.0000],\n",
      "        [297.4997, 248.1392, 342.2975, 356.0720],\n",
      "        [299.0325, 307.6533, 347.2774, 357.3348]]), 'labels': tensor([1, 1, 1]), 'scores': tensor([0.9957, 0.8322, 0.1336])}]\n"
     ]
    }
   ],
   "source": [
    "# pick one image from the test set\n",
    "img, _ = dataset_test[8]\n",
    "# put the model in evaluation mode\n",
    "model1.eval()\n",
    "with torch.no_grad():\n",
    "    prediction1 = model1([img.to(device)])\n",
    "\n",
    "print(prediction1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the output results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Loading the image corresponding to the boxes (test set)\n",
    "img2 = cv2.imread(\"custom_dataset/JPGImages/\" + list_files[_[\"image_id\"][0]])\n",
    "\n",
    "# Creating rectangle\n",
    "for i in range(len(prediction1[0][\"boxes\"])):\n",
    "    cv2.rectangle(img2, (int(prediction1[0][\"boxes\"][i][0]), int(prediction1[0][\"boxes\"][i][1])), (int(prediction1[0][\"boxes\"][i][2]), int(prediction1[0][\"boxes\"][i][3])), (0, 0, 255), 3)\n",
    "\n",
    "cv2.imshow('result', img2) \n",
    "  \n",
    "# Allows us to see image \n",
    "# until closed forcefully \n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminating the low scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "tensor([24])\n",
      "fig11100_13.20.00.jpg\n",
      "tensor([[301., 238., 347., 360.],\n",
      "        [505., 240., 613., 360.]])\n"
     ]
    }
   ],
   "source": [
    "# print(prediction1[0][\"scores\"])\n",
    "# prediction1[0][\"scores\"] > 0.9\n",
    "# print(prediction1[0][\"boxes\"][prediction1[0][\"scores\"] > 0.9])\n",
    "\n",
    "picks = non_max_suppression_slow(prediction1[0][\"boxes\"][prediction1[0][\"scores\"] > 0.80].cpu(), 0.3)\n",
    "\n",
    "print(picks)\n",
    "print(_[\"image_id\"])\n",
    "\n",
    "print(list_files[_[\"image_id\"][0]])\n",
    "\n",
    "print(_[\"boxes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non max suppression (eliminate the duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#non-max suppression, cf pyimageresearch\n",
    "\n",
    "# import the necessary packages\n",
    "import numpy as np\n",
    "    \n",
    "#  Felzenszwalb et al.\n",
    "def non_max_suppression_slow(boxes, overlapThresh):\n",
    "    # if there are no boxes, return an empty list\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    " \n",
    "    # initialize the list of picked indexes\n",
    "    pick = []\n",
    " \n",
    "    # grab the coordinates of the bounding boxes\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    " \n",
    "    # compute the area of the bounding boxes and sort the bounding\n",
    "    # boxes by the bottom-right y-coordinate of the bounding box\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(y2)\n",
    "\n",
    "    \n",
    "    # keep looping while some indexes still remain in the indexes\n",
    "    # list\n",
    "    while len(idxs) > 0:\n",
    "        # grab the last index in the indexes list, add the index\n",
    "        # value to the list of picked indexes, then initialize\n",
    "        # the suppression list (i.e. indexes that will be deleted)\n",
    "        # using the last index\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "        suppress = [last]\n",
    "\n",
    "\n",
    "        # loop over all indexes in the indexes list\n",
    "        for pos in range(0, last):\n",
    "            # grab the current index\n",
    "            j = idxs[pos]\n",
    " \n",
    "            # find the largest (x, y) coordinates for the start of\n",
    "            # the bounding box and the smallest (x, y) coordinates\n",
    "            # for the end of the bounding box\n",
    "            xx1 = max(x1[i], x1[j])\n",
    "            yy1 = max(y1[i], y1[j])\n",
    "            xx2 = min(x2[i], x2[j])\n",
    "            yy2 = min(y2[i], y2[j])\n",
    " \n",
    "            # compute the width and height of the bounding box\n",
    "            w = max(0, xx2 - xx1 + 1)\n",
    "            h = max(0, yy2 - yy1 + 1)\n",
    " \n",
    "            # compute the ratio of overlap between the computed\n",
    "            # bounding box and the bounding box in the area list\n",
    "            overlap = float(w * h) / area[j]\n",
    "\n",
    "            # if there is sufficient overlap, suppress the\n",
    "            # current bounding box\n",
    "            if overlap > overlapThresh:\n",
    "                suppress.append(pos)\n",
    " \n",
    "        # delete all indexes from the index list that are in the\n",
    "        # suppression list\n",
    "        idxs = np.delete(idxs, suppress)\n",
    "     \n",
    "    return [int(p) for p in pick]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels, to compare with prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([24])\n",
      "fig11100_13.20.00.jpg\n",
      "tensor([[301., 238., 347., 360.],\n",
      "        [505., 240., 613., 360.]])\n"
     ]
    }
   ],
   "source": [
    "print(_[\"image_id\"])\n",
    "\n",
    "print(list_files[_[\"image_id\"][0]])\n",
    "\n",
    "print(_[\"boxes\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing the results on the corresponding image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "tensor([[500.9510, 243.8863, 615.6051, 360.0000],\n",
      "        [297.4997, 248.1392, 342.2975, 356.0720]])\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "bboxes = prediction1[0][\"boxes\"]\n",
    "# print(bboxes)\n",
    "\n",
    "print(picks)\n",
    "\n",
    "remaining_bboxes = bboxes[picks]\n",
    "print(remaining_bboxes)\n",
    "\n",
    "\n",
    "# Loading the image corresponding to the boxes (test set)\n",
    "img2 = cv2.imread(\"custom_dataset/JPGImages/\" + list_files[_[\"image_id\"][0]])\n",
    "\n",
    "# Creating rectangle\n",
    "for i in range(len(picks)):\n",
    "    cv2.rectangle(img2, (int(remaining_bboxes[i][0]), int(remaining_bboxes[i][1])), (int(remaining_bboxes[i][2]), int(remaining_bboxes[i][3])), (0, 255, 0), 3)\n",
    "\n",
    "cv2.imshow('result', img2) \n",
    "  \n",
    "# Allows us to see image \n",
    "# until closed forcefully \n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
